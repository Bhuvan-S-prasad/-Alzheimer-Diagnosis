{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib # For saving models\n",
    "import yaml # For config file loading\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\bhuva\\Desktop\\Alziemer\\config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "PROCESSED_DATA_DIR = config[\"processed_data_dir\"] \n",
    "MODEL_DIR = config[\"model_dir\"] \n",
    "RANDOM_STATE = config[\"random_state\"]\n",
    "METRICS_FILE = config[\"metrics_file\"] \n",
    "HYPERPARAMETER_TUNING = config.get(\"hyperparameter_tuning\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "random_forest_param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15, None]}\n",
    "xgboost_param_grid = {'n_estimators': [100, 200], 'max_depth': [3, 6], 'learning_rate': [0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, model_type, param_grid=None, random_state=42):\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    if HYPERPARAMETER_TUNING and param_grid: \n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1) \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best hyperparameters for {model_type}: {grid_search.best_params_}\")\n",
    "        model = best_model\n",
    "    else:\n",
    "        model.fit(X_train, y_train) \n",
    "\n",
    "    # --- Evaluation ---\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_val_prob = model.predict_proba(X_val)[:, 1] # Probabilities for ROC AUC\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"\\n--- {model_type.upper()} ---\")\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    print(classification_report(y_val, y_val_pred)) \n",
    "    print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "    print(f\"Validation AUC-ROC: {roc_auc_score(y_val, y_val_prob):.4f}\")\n",
    "\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Test AUC-ROC: {roc_auc_score(y_test, y_test_prob):.4f}\")\n",
    "\n",
    "    # --- ROC Curve Plot ---\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_test_prob):.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_type.upper()}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"C:/Users/bhuva/Desktop/Alziemer/reports/{model_type}_roc_curve.png\") #ROC curve plot in reports directory \n",
    "    plt.close() # Close plot to free memory\n",
    "\n",
    "    # --- Save Metrics to File ---\n",
    "    metrics = {\n",
    "        f\"{model_type}_validation_accuracy\": accuracy_score(y_val, y_val_pred),\n",
    "        f\"{model_type}_validation_auc_roc\": roc_auc_score(y_val, y_val_prob),\n",
    "        f\"{model_type}_test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        f\"{model_type}_test_auc_roc\": roc_auc_score(y_test, y_test_prob),\n",
    "    }\n",
    "    return model, metrics # Return trained model and metrics dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for random_forest: {'max_depth': 15, 'n_estimators': 300}\n",
      "\n",
      "--- RANDOM_FOREST ---\n",
      "\n",
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77      6535\n",
      "           1       0.67      0.62      0.64      4607\n",
      "\n",
      "    accuracy                           0.72     11142\n",
      "   macro avg       0.71      0.70      0.70     11142\n",
      "weighted avg       0.71      0.72      0.71     11142\n",
      "\n",
      "Validation Accuracy: 0.7167\n",
      "Validation AUC-ROC: 0.7946\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      6536\n",
      "           1       0.68      0.63      0.66      4607\n",
      "\n",
      "    accuracy                           0.73     11143\n",
      "   macro avg       0.72      0.71      0.72     11143\n",
      "weighted avg       0.73      0.73      0.73     11143\n",
      "\n",
      "Test Accuracy: 0.7275\n",
      "Test AUC-ROC: 0.8022\n",
      "Trained models saved to 'models/trained_models.joblib'\n",
      "Model metrics saved to 'C:/Users/bhuva/Desktop/Alziemer/reports/model_metrics.json'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load processed data \n",
    "    X_train_processed = pd.read_csv(f\"{PROCESSED_DATA_DIR}/X_train_processed.csv\")\n",
    "    X_val_processed = pd.read_csv(f\"{PROCESSED_DATA_DIR}/X_val_processed.csv\")\n",
    "    X_test_processed = pd.read_csv(f\"{PROCESSED_DATA_DIR}/X_test_processed.csv\")\n",
    "    y_train = pd.read_csv(f\"{PROCESSED_DATA_DIR}/y_train.csv\")\n",
    "    y_val = pd.read_csv(f\"{PROCESSED_DATA_DIR}/y_val.csv\")\n",
    "    y_test = pd.read_csv(f\"{PROCESSED_DATA_DIR}/y_test.csv\")\n",
    "    y_train = y_train.squeeze() # Convert DataFrame to Series\n",
    "    y_val = y_val.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "\n",
    "    # Train and Evaluate Models & Save \n",
    "    trained_models = {}\n",
    "    all_metrics = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model, rf_metrics = train_and_evaluate_model(X_train_processed, y_train, X_val_processed, y_val, X_test_processed, y_test,\n",
    "                                                    model_type='random_forest', param_grid=random_forest_param_grid if HYPERPARAMETER_TUNING else None, random_state=RANDOM_STATE)\n",
    "    trained_models['random_forest'] = rf_model\n",
    "    all_metrics.update(rf_metrics)\n",
    "\n",
    "\n",
    "\n",
    "    # Save Trained Models \n",
    "    joblib.dump(trained_models, f\"{MODEL_DIR}/trained_models.joblib\")\n",
    "    print(\"Trained models saved to 'models/trained_models.joblib'\")\n",
    "\n",
    "    # Save Metrics to JSON \n",
    "    import json\n",
    "    with open(METRICS_FILE, 'w') as outfile:\n",
    "        json.dump(all_metrics, outfile, indent=4)\n",
    "    print(f\"Model metrics saved to '{METRICS_FILE}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
